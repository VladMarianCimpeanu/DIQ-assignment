{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b118da78",
   "metadata": {},
   "source": [
    "# Data & Information quality assignment\n",
    "\n",
    "TODO:\n",
    "- perform data quality assesment using the following metrics:\n",
    "    - completeness\n",
    "- perform data imputation\n",
    "- perform data quality assessment again:\n",
    "    - completeness\n",
    "    - accuracy\n",
    "    \n",
    "- perform ML quality analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69ef9d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import utility.dirty_completeness as dirty_completeness\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer, KNNImputer, IterativeImputer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "SEED = 122\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a9f0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_heatmap(model, X, y):\n",
    "    \"\"\"\n",
    "    This method generates an heatmap used by seaborn to create a confusion matrix.\n",
    "    :param model: model for which the method computes the confusion matrix.\n",
    "    :param validation_generator: dataset object over which the model computes its predictions.\n",
    "    :param ensemble: Optional argument. If ensemble is True, it computes the confusion matrix using\n",
    "    a selfe-ensemble method with 5 voters.\n",
    "    :return pd.DataFrame object containing the confusion matrix.\n",
    "    \"\"\"\n",
    "    y_predicted = model.predict(X)\n",
    "    y_predicted = np.argmax(y_predicted, axis=1)\n",
    "\n",
    "    y_test_labels = tf.argmax(y, axis=1)\n",
    "    \n",
    "    confusion_matrix = confusion_matrix(\n",
    "        y_test_labels, \n",
    "        y_predicted,\n",
    "    )\n",
    "    c = []\n",
    "    for item in confusion_matrix:\n",
    "        c.append(np.around(item / np.sum(item), decimals=3))\n",
    "    df_heatmap = pd.DataFrame(c)\n",
    "    return df_heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1858ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_report(model, test):\n",
    "  \"\"\"\n",
    "  Compute recall, precision and f1-score for each class, for a model predicting\n",
    "  on a given set.\n",
    "  :param model: model to evaluate\n",
    "  :param test: test set over which this method evaluate the input model.\n",
    "  :return a pandas dataframe containing precision, recall and f1-score of the model.\n",
    "  \"\"\"\n",
    "\n",
    "  # compute predictions\n",
    "  y_pred = model.predict(test)\n",
    "  y_pred = tf.argmax(y_pred, axis=1)\n",
    "\n",
    "  # get true labels\n",
    "  y_true = np.concatenate([y for x, y in test], axis=0)\n",
    "  y_true = tf.argmax(y_true, axis=1)\n",
    "\n",
    "  # return report  \n",
    "  report = classification_report(y_true,\n",
    "                                 y_pred,\n",
    "                                 target_names=['n', 'p', 't'],\n",
    "                                 output_dict=True)\n",
    "  \n",
    "  report = pd.DataFrame(report)\n",
    "  report = report.drop(['accuracy',\t'macro avg',\t'weighted avg'], axis=1)\n",
    "  return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13ead711",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>plant-stand</th>\n",
       "      <th>precip</th>\n",
       "      <th>temp</th>\n",
       "      <th>hail</th>\n",
       "      <th>crop-hist</th>\n",
       "      <th>area-damaged</th>\n",
       "      <th>severity</th>\n",
       "      <th>seed-tmt</th>\n",
       "      <th>germination</th>\n",
       "      <th>...</th>\n",
       "      <th>sclerotia</th>\n",
       "      <th>fruit-pods</th>\n",
       "      <th>fruit-spots</th>\n",
       "      <th>seed</th>\n",
       "      <th>mold-growth</th>\n",
       "      <th>seed-discolor</th>\n",
       "      <th>seed-size</th>\n",
       "      <th>shriveling</th>\n",
       "      <th>roots</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>october</td>\n",
       "      <td>normal</td>\n",
       "      <td>gt-norm</td>\n",
       "      <td>norm</td>\n",
       "      <td>yes</td>\n",
       "      <td>same-lst-yr</td>\n",
       "      <td>low-areas</td>\n",
       "      <td>pot-severe</td>\n",
       "      <td>none</td>\n",
       "      <td>90-100</td>\n",
       "      <td>...</td>\n",
       "      <td>absent</td>\n",
       "      <td>norm</td>\n",
       "      <td>dna</td>\n",
       "      <td>norm</td>\n",
       "      <td>absent</td>\n",
       "      <td>absent</td>\n",
       "      <td>norm</td>\n",
       "      <td>absent</td>\n",
       "      <td>norm</td>\n",
       "      <td>diaporthe-stem-canker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>august</td>\n",
       "      <td>normal</td>\n",
       "      <td>gt-norm</td>\n",
       "      <td>norm</td>\n",
       "      <td>yes</td>\n",
       "      <td>same-lst-two-yrs</td>\n",
       "      <td>scattered</td>\n",
       "      <td>severe</td>\n",
       "      <td>fungicide</td>\n",
       "      <td>80-89</td>\n",
       "      <td>...</td>\n",
       "      <td>absent</td>\n",
       "      <td>norm</td>\n",
       "      <td>dna</td>\n",
       "      <td>norm</td>\n",
       "      <td>absent</td>\n",
       "      <td>absent</td>\n",
       "      <td>norm</td>\n",
       "      <td>absent</td>\n",
       "      <td>norm</td>\n",
       "      <td>diaporthe-stem-canker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>july</td>\n",
       "      <td>normal</td>\n",
       "      <td>gt-norm</td>\n",
       "      <td>norm</td>\n",
       "      <td>yes</td>\n",
       "      <td>same-lst-yr</td>\n",
       "      <td>scattered</td>\n",
       "      <td>severe</td>\n",
       "      <td>fungicide</td>\n",
       "      <td>lt-80</td>\n",
       "      <td>...</td>\n",
       "      <td>absent</td>\n",
       "      <td>norm</td>\n",
       "      <td>dna</td>\n",
       "      <td>norm</td>\n",
       "      <td>absent</td>\n",
       "      <td>absent</td>\n",
       "      <td>norm</td>\n",
       "      <td>absent</td>\n",
       "      <td>norm</td>\n",
       "      <td>diaporthe-stem-canker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>july</td>\n",
       "      <td>normal</td>\n",
       "      <td>gt-norm</td>\n",
       "      <td>norm</td>\n",
       "      <td>yes</td>\n",
       "      <td>same-lst-yr</td>\n",
       "      <td>scattered</td>\n",
       "      <td>severe</td>\n",
       "      <td>none</td>\n",
       "      <td>80-89</td>\n",
       "      <td>...</td>\n",
       "      <td>absent</td>\n",
       "      <td>norm</td>\n",
       "      <td>dna</td>\n",
       "      <td>norm</td>\n",
       "      <td>absent</td>\n",
       "      <td>absent</td>\n",
       "      <td>norm</td>\n",
       "      <td>absent</td>\n",
       "      <td>norm</td>\n",
       "      <td>diaporthe-stem-canker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>october</td>\n",
       "      <td>normal</td>\n",
       "      <td>gt-norm</td>\n",
       "      <td>norm</td>\n",
       "      <td>yes</td>\n",
       "      <td>same-lst-two-yrs</td>\n",
       "      <td>scattered</td>\n",
       "      <td>pot-severe</td>\n",
       "      <td>none</td>\n",
       "      <td>lt-80</td>\n",
       "      <td>...</td>\n",
       "      <td>absent</td>\n",
       "      <td>norm</td>\n",
       "      <td>dna</td>\n",
       "      <td>norm</td>\n",
       "      <td>absent</td>\n",
       "      <td>absent</td>\n",
       "      <td>norm</td>\n",
       "      <td>absent</td>\n",
       "      <td>norm</td>\n",
       "      <td>diaporthe-stem-canker</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      date plant-stand   precip  temp hail         crop-hist area-damaged  \\\n",
       "0  october      normal  gt-norm  norm  yes       same-lst-yr    low-areas   \n",
       "1   august      normal  gt-norm  norm  yes  same-lst-two-yrs    scattered   \n",
       "2     july      normal  gt-norm  norm  yes       same-lst-yr    scattered   \n",
       "3     july      normal  gt-norm  norm  yes       same-lst-yr    scattered   \n",
       "4  october      normal  gt-norm  norm  yes  same-lst-two-yrs    scattered   \n",
       "\n",
       "     severity   seed-tmt germination  ... sclerotia fruit-pods fruit-spots  \\\n",
       "0  pot-severe       none      90-100  ...    absent       norm         dna   \n",
       "1      severe  fungicide       80-89  ...    absent       norm         dna   \n",
       "2      severe  fungicide       lt-80  ...    absent       norm         dna   \n",
       "3      severe       none       80-89  ...    absent       norm         dna   \n",
       "4  pot-severe       none       lt-80  ...    absent       norm         dna   \n",
       "\n",
       "   seed mold-growth seed-discolor seed-size shriveling roots  \\\n",
       "0  norm      absent        absent      norm     absent  norm   \n",
       "1  norm      absent        absent      norm     absent  norm   \n",
       "2  norm      absent        absent      norm     absent  norm   \n",
       "3  norm      absent        absent      norm     absent  norm   \n",
       "4  norm      absent        absent      norm     absent  norm   \n",
       "\n",
       "                   class  \n",
       "0  diaporthe-stem-canker  \n",
       "1  diaporthe-stem-canker  \n",
       "2  diaporthe-stem-canker  \n",
       "3  diaporthe-stem-canker  \n",
       "4  diaporthe-stem-canker  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soybean_df = pd.read_csv('../datasets/soybean.csv')\n",
    "soybean_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa6bfaf",
   "metadata": {},
   "source": [
    "Exploratory analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6913e3da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date                7\n",
       "plant-stand         2\n",
       "precip              3\n",
       "temp                3\n",
       "hail                2\n",
       "crop-hist           4\n",
       "area-damaged        4\n",
       "severity            3\n",
       "seed-tmt            3\n",
       "germination         3\n",
       "plant-growth        2\n",
       "leaves              2\n",
       "leafspots-halo      3\n",
       "leafspots-marg      3\n",
       "leafspot-size       3\n",
       "leaf-spread         2\n",
       "leaf-malf           2\n",
       "leaf-mild           3\n",
       "stem                2\n",
       "lodging             2\n",
       "stem-cankers        4\n",
       "canker-lesion       4\n",
       "fruiting-bodies     2\n",
       "external-decay      2\n",
       "mycelium            2\n",
       "int-discolor        3\n",
       "sclerotia           2\n",
       "fruit-pods          3\n",
       "fruit-spots         4\n",
       "seed                2\n",
       "mold-growth         2\n",
       "seed-discolor       2\n",
       "seed-size           2\n",
       "shriveling          2\n",
       "roots               3\n",
       "class              15\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soybean_df.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005ab7df",
   "metadata": {},
   "source": [
    "From the [Dataset documentation](https://archive.ics.uci.edu/ml/datasets/Soybean+(Large)) we can look at the values each variable can take. We can deduce that almost all the variables are categorical.\\\n",
    "Features that are not categorical are:\n",
    "\n",
    "cyclic features:\n",
    "- date\n",
    "\n",
    "ordinal features:\n",
    "- plant-stand\n",
    "- precip\n",
    "- temp\n",
    "- germination\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4e1ef3",
   "metadata": {},
   "source": [
    "## Injection of null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66f6d41f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved -completeness50%\n",
      "saved -completeness60%\n",
      "saved -completeness70%\n",
      "saved -completeness80%\n",
      "saved -completeness90%\n"
     ]
    }
   ],
   "source": [
    "df_s = dirty_completeness.injection(soybean_df, SEED, name='', name_class='class')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7d87e7",
   "metadata": {},
   "source": [
    "## Data quality assesment before the imputation.\n",
    "\n",
    "In this section, first we make a data quality assesment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "752d528a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5119366354306114,\n",
       " 0.6105533244087461,\n",
       " 0.7038152610441767,\n",
       " 0.8046630968317715,\n",
       " 0.9043953592146363]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completeness_degree = [1 - df.isnull().sum().sum() / (df.shape[0] * df.shape[1]) for df in df_s]\n",
    "completeness_degree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de87f80",
   "metadata": {},
   "source": [
    "## Basic imputation method.\n",
    "\n",
    "Since there are a lot of categorical features, we believe a good basic imputation method could be to fill each NaN value with the mode of its belonging column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2e79325",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_df_s = []\n",
    "\n",
    "for n, df in enumerate(df_s):\n",
    "    simple_imputer = SimpleImputer(missing_values=np.NaN, strategy='most_frequent')\n",
    "    imputed_df = simple_imputer.fit_transform(df)\n",
    "    imputed_df = pd.DataFrame(imputed_df, columns=df.columns)\n",
    "    imputed_df_s.append(imputed_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae33c06",
   "metadata": {},
   "source": [
    "## Data quality assesment after the data imputation.\n",
    "\n",
    "First, we check that the completeness is 1 for each dataframe, after the imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17e04539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The completeness degree for each impute dataframe is [1.0, 1.0, 1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "completeness_degree = [1 - df.isnull().sum().sum() / (df.shape[0] * df.shape[1]) for df in imputed_df_s]\n",
    "print(f\"The completeness degree for each impute dataframe is {completeness_degree}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27465cd2",
   "metadata": {},
   "source": [
    "Now, we compute the accuracy. First we mesure it using the exact matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b1c6f5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_assesment(imputed_df_s: list, original_df, numeric_columns=[]) -> list:\n",
    "    \"\"\"\n",
    "    This method compute the accuracy of the imputed dataframes with respect to the original dataframe.\n",
    "    :param imputed_df_s: list of imputed pandas dataframes.\n",
    "    :param original_df: pandas dataframe taken as reference when computing the accuracy.\n",
    "    :param numeric_columns: list of column names that have a numeric value.\n",
    "    :return: list of accuracies.\n",
    "    \"\"\"\n",
    "\n",
    "    columns = original_df.columns\n",
    "    \n",
    "    accuracies = []\n",
    "    \n",
    "    tot_size = original_df.shape[0] * original_df.shape[1] \n",
    "    \n",
    "    for i_df in imputed_df_s:\n",
    "        distance_error = 0\n",
    "        for c in columns:\n",
    "            \n",
    "            # defining distance function based on the type of variable.\n",
    "            if c in numeric_columns:\n",
    "                maximum_distance = original_df[c].max() - original_df[c].min()\n",
    "                distance_function = lambda x, y: (np.abs(x - y) / maximum_distance) \n",
    "            else:\n",
    "                distance_function = lambda x, y: 1 if x != y else 0\n",
    "            \n",
    "            # retriving values for a specific column\n",
    "            imputed_column = pd.Series(i_df[c]).values\n",
    "            original_column = pd.Series(original_df[c]).values\n",
    "            \n",
    "            # compare columns\n",
    "            for i, o in zip(imputed_column, original_column):\n",
    "                distance_error += distance_function(i, o)\n",
    "                \n",
    "       \n",
    "        accuracy = (tot_size - distance_error) / tot_size\n",
    "        accuracies.append(accuracy)\n",
    "\n",
    "    return accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "33e1e923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.858433734939759,\n",
       " 0.8866577420794288,\n",
       " 0.9132083891120035,\n",
       " 0.9424364123159303,\n",
       " 0.9721106648817492]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_assesment(imputed_df_s, soybean_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be058cb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.858433734939759,\n",
       " 0.8866577420794288,\n",
       " 0.9132083891120035,\n",
       " 0.9424364123159303,\n",
       " 0.9721106648817492]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = soybean_df.columns\n",
    "\n",
    "accuracies = []\n",
    "for i_df in imputed_df_s:\n",
    "    distance_error = 0\n",
    "    for c in columns:\n",
    "        imputed_column = pd.Series(i_df[c]).values\n",
    "        original_column = pd.Series(soybean_df[c]).values\n",
    "        for i, o in zip(imputed_column, original_column):\n",
    "            if i != o:\n",
    "                distance_error += 1\n",
    "    tot_size = df.shape[0] * df.shape[1]        \n",
    "    accuracy = (tot_size - distance_error) / tot_size\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f88a5ce",
   "metadata": {},
   "source": [
    "For the accuracy assesment based on the distance, we can convert the ordinal and cyclic variables to numerical values and mesure the accuracy bases on the distance between their values.\n",
    "\n",
    "\n",
    "Date is cyclic variable, thus, we can transform it using a sinusoidal transformation with frequency equal to 12 (date represents months).\n",
    "\n",
    "\n",
    "$x = to\\_ordinal(date)$\n",
    "\n",
    "\n",
    "$y = sin(\\frac{1}{12}x)$\n",
    "\n",
    "From the [Dataset documentation](https://archive.ics.uci.edu/ml/datasets/Soybean+(Large)), the following ordinal features have the domain in the table:\n",
    "- plant-stand\n",
    "- precip\n",
    "- temp\n",
    "- germination\n",
    "- severity\n",
    "\n",
    "| features | original domain | ordinal domain |\n",
    "| --- | --- | --- |\n",
    "|plant-stand|lt-norm, norm, gt-norm|0, 1, 2|\n",
    "|precip|lt-norm, norm, gt-norm|0, 1, 2|\n",
    "|temp|lt-norm, norm, gt-norm|0, 1, 2|\n",
    "|germination|lt-80%, 80-89%, 90-100%|0, 1, 2|\n",
    "|severity|minor, pot-severe, severe|0, 1, 2|\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
